{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6311b35d-8f53-4cde-9366-5a847d4d738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\bernie\\anaconda3\\lib\\site-packages (25.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\bernie\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bernie\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "# At the top of your notebook, run:\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Then install TensorFlow:\n",
    "!python -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75f91cb-098f-4600-a8d3-fad3a203f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load the data\n",
    "# ---------------------------\n",
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53df0369-f071-48a1-a60c-c0b2f33c7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 2: Feature engineering\n",
    "# ---------------------------\n",
    "def extract_deck(cabin):\n",
    "    if pd.isnull(cabin):\n",
    "        return \"Missing\"\n",
    "    return cabin.split('/')[0]\n",
    "\n",
    "for df in (train, test):\n",
    "    # 2a) Deck from Cabin\n",
    "    df['Deck'] = df['Cabin'].apply(extract_deck)\n",
    "\n",
    "    # 2b) CryoSleep & VIP → pandas nullable Boolean → fillna → int(0/1)\n",
    "    for col in ['CryoSleep', 'VIP']:\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "              .replace({'True': True, 'False': False})\n",
    "              .astype('boolean')    # pandas’ nullable Boolean\n",
    "              .fillna(False)        # fills <NA> with False\n",
    "              .astype(int)          # True→1, False→0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af5cea9-0257-49a2-bbde-8b407f11cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 3: Define X, y\n",
    "# ---------------------------\n",
    "# Target: Transported → 1 if True, 0 if False\n",
    "y = train['Transported'].map({True:1, False:0})\n",
    "\n",
    "# Drop cols we won’t feed into the model\n",
    "drop_cols = ['PassengerId','Name','Cabin','Transported']\n",
    "X = train.drop(drop_cols, axis=1)\n",
    "X_test = test.drop(['PassengerId','Name','Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a52cf96-cd9f-417b-9840-3af57a801ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 4: Preprocessing pipeline\n",
    "# ---------------------------\n",
    "numeric_features = ['Age','RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',   StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['HomePlanet','Destination','Deck']\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot',  OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline,     numeric_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Fit the preprocessor on X, transform X and X_test\n",
    "X_proc = preprocessor.fit_transform(X)\n",
    "X_test_proc = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f298f1-b47e-43f6-b08b-dab85bd1c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 5: Train/validation split\n",
    "# ---------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_proc, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e306af52-d0a5-474f-8b6e-a4044517307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 6: Build the neural network\n",
    "# ---------------------------\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    # 1) Explicit Input layer\n",
    "    Input(shape=(input_dim,)),        \n",
    "\n",
    "    # 2) Hidden layers\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # 3) Output layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping on validation loss\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c3eaf9-211f-40cc-9a52-a0599f77ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "218/218 - 1s - 7ms/step - accuracy: 0.6898 - loss: 0.5722 - val_accuracy: 0.7780 - val_loss: 0.4566\n",
      "Epoch 2/100\n",
      "218/218 - 0s - 2ms/step - accuracy: 0.7660 - loss: 0.4768 - val_accuracy: 0.7849 - val_loss: 0.4401\n",
      "Epoch 3/100\n",
      "218/218 - 0s - 2ms/step - accuracy: 0.7748 - loss: 0.4617 - val_accuracy: 0.7964 - val_loss: 0.4276\n",
      "Epoch 4/100\n",
      "218/218 - 0s - 2ms/step - accuracy: 0.7785 - loss: 0.4526 - val_accuracy: 0.7918 - val_loss: 0.4236\n",
      "Epoch 5/100\n",
      "218/218 - 0s - 2ms/step - accuracy: 0.7813 - loss: 0.4475 - val_accuracy: 0.8010 - val_loss: 0.4198\n",
      "Epoch 6/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7852 - loss: 0.4408 - val_accuracy: 0.8016 - val_loss: 0.4154\n",
      "Epoch 7/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7900 - loss: 0.4367 - val_accuracy: 0.7982 - val_loss: 0.4149\n",
      "Epoch 8/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7866 - loss: 0.4305 - val_accuracy: 0.7987 - val_loss: 0.4132\n",
      "Epoch 9/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7869 - loss: 0.4278 - val_accuracy: 0.7987 - val_loss: 0.4110\n",
      "Epoch 10/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7957 - loss: 0.4283 - val_accuracy: 0.8016 - val_loss: 0.4136\n",
      "Epoch 11/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7840 - loss: 0.4320 - val_accuracy: 0.8010 - val_loss: 0.4100\n",
      "Epoch 12/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7964 - loss: 0.4266 - val_accuracy: 0.7947 - val_loss: 0.4109\n",
      "Epoch 13/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7980 - loss: 0.4238 - val_accuracy: 0.8022 - val_loss: 0.4095\n",
      "Epoch 14/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7949 - loss: 0.4205 - val_accuracy: 0.8028 - val_loss: 0.4090\n",
      "Epoch 15/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7926 - loss: 0.4235 - val_accuracy: 0.8039 - val_loss: 0.4092\n",
      "Epoch 16/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7978 - loss: 0.4207 - val_accuracy: 0.8016 - val_loss: 0.4092\n",
      "Epoch 17/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7942 - loss: 0.4214 - val_accuracy: 0.8028 - val_loss: 0.4087\n",
      "Epoch 18/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7929 - loss: 0.4218 - val_accuracy: 0.7999 - val_loss: 0.4090\n",
      "Epoch 19/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7965 - loss: 0.4198 - val_accuracy: 0.8010 - val_loss: 0.4096\n",
      "Epoch 20/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7977 - loss: 0.4212 - val_accuracy: 0.8045 - val_loss: 0.4094\n",
      "Epoch 21/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7980 - loss: 0.4166 - val_accuracy: 0.8079 - val_loss: 0.4091\n",
      "Epoch 22/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7981 - loss: 0.4183 - val_accuracy: 0.8068 - val_loss: 0.4085\n",
      "Epoch 23/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7923 - loss: 0.4174 - val_accuracy: 0.8062 - val_loss: 0.4097\n",
      "Epoch 24/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7990 - loss: 0.4179 - val_accuracy: 0.8074 - val_loss: 0.4082\n",
      "Epoch 25/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7938 - loss: 0.4182 - val_accuracy: 0.8033 - val_loss: 0.4104\n",
      "Epoch 26/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.8011 - loss: 0.4132 - val_accuracy: 0.8056 - val_loss: 0.4096\n",
      "Epoch 27/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7984 - loss: 0.4115 - val_accuracy: 0.8016 - val_loss: 0.4083\n",
      "Epoch 28/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7964 - loss: 0.4121 - val_accuracy: 0.8016 - val_loss: 0.4086\n",
      "Epoch 29/100\n",
      "218/218 - 0s - 1ms/step - accuracy: 0.7974 - loss: 0.4157 - val_accuracy: 0.8005 - val_loss: 0.4096\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 7: Train\n",
    "# ---------------------------\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[es],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f719a2-e154-4e82-b775-bb1ce46e1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step\n",
      "Saved submission_neural_network.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Step 8: Predict & submit\n",
    "# ---------------------------\n",
    "probs = model.predict(X_test_proc).ravel()\n",
    "preds = (probs >= 0.5).astype(bool)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Transported': preds\n",
    "})\n",
    "submission.to_csv('submission_neural_network.csv', index=False)\n",
    "print(\"Saved submission_neural_network.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb768fd3-09ed-4aaf-9431-ea61cb8bc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
